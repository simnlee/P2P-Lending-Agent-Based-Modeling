{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchrl.envs import EnvBase\n",
    "from torchrl.data import TensorSpec, CompositeSpec\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define Borrower Agent\n",
    "class BorrowerAgent(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(BorrowerAgent, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),  # Output proposed interest rate\n",
    "            nn.Sigmoid()       # Ensure output is between 0 and 1 (interest rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 6 + self.model(x) * 30  # Scale interest rate to 6-36%\n",
    "\n",
    "# Define Lender Agent\n",
    "class LenderAgent(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(LenderAgent, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(5*feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 5),  # Output funding decisions for all borrowers\n",
    "            nn.Softmax()       # Probability distribution of choosing borrower to fund\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "        init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Random Sample of Borrowers from Lending Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv('data/LC_top20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip loan status 0 to 1 and 1 to 0\n",
    "raw_data['loan_status'] = 1 - raw_data['loan_status']\n",
    "# get proportion of default loans (equal to 1)\n",
    "default_proportion = raw_data['loan_status'].value_counts(normalize=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    1076751\n",
       "1     268599\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std of each feature\n",
    "x_borrower = raw_data.drop(columns=['loan_status', 'int_rate'])\n",
    "x_borrower = x_borrower.astype(np.float32)\n",
    "mean_borrower = torch.tensor(x_borrower.mean().values)\n",
    "std_borrower = torch.tensor(x_borrower.std().values)\n",
    "\n",
    "x_lender = raw_data.drop(columns=['loan_status'])\n",
    "x_lender = x_lender.astype(np.float32)\n",
    "mean_lender = torch.tensor(x_lender.mean().values)\n",
    "std_lender = torch.tensor(x_lender.std().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_borrower(x):\n",
    "    return torch.div(torch.sub(x, mean_borrower), std_borrower)\n",
    "def normalize_lender(x):\n",
    "    return torch.div(torch.sub(x, mean_lender), std_lender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random sample of 5 loans where 4 are paid off and 1 is defaulted\n",
    "default_loans = raw_data[raw_data['loan_status'] == 0]\n",
    "paid_loans = raw_data[raw_data['loan_status'] == 1]\n",
    "sample = pd.concat([default_loans.sample(1), paid_loans.sample(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.drop(columns=['int_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>dti</th>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>num_accts_ever_120_pd</th>\n",
       "      <th>all_util</th>\n",
       "      <th>num_rev_tl_bal_gt_0</th>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>open_act_il</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>num_bc_sats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51090</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.85</td>\n",
       "      <td>329.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>89500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47767.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.176122</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.79254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013926</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>24.13</td>\n",
       "      <td>138.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20883.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.176122</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.79254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779042</th>\n",
       "      <td>13600.0</td>\n",
       "      <td>60</td>\n",
       "      <td>19.17</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>True</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.176122</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.79254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295164</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>28.99</td>\n",
       "      <td>288.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29700.0</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4526.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.176122</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.79254</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124251</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>13.46</td>\n",
       "      <td>134.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.176122</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.79254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loan_amnt  term    dti  mo_sin_old_rev_tl_op  acc_open_past_24mths  \\\n",
       "51090      30000.0    36  11.85                 329.0                   3.0   \n",
       "1013926    25000.0    36  24.13                 138.0                   3.0   \n",
       "779042     13600.0    60  19.17                 198.0                   1.0   \n",
       "295164     15000.0    60  28.99                 288.0                  10.0   \n",
       "1124251    10000.0    36  13.46                 134.0                   3.0   \n",
       "\n",
       "         total_bc_limit  home_ownership_RENT  annual_inc  delinq_2yrs  \\\n",
       "51090           89500.0                False    120000.0          0.0   \n",
       "1013926         17300.0                False     79000.0          0.0   \n",
       "779042           6200.0                 True     36000.0          0.0   \n",
       "295164          29700.0                False    100000.0          1.0   \n",
       "1124251         12900.0                 True     42000.0          0.0   \n",
       "\n",
       "         avg_cur_bal  num_accts_ever_120_pd   all_util  num_rev_tl_bal_gt_0  \\\n",
       "51090        47767.0                    0.0  58.176122                  3.0   \n",
       "1013926      20883.0                    1.0  58.176122                  9.0   \n",
       "779042        6485.0                    0.0  58.176122                  3.0   \n",
       "295164        4526.0                    0.0  58.176122                  8.0   \n",
       "1124251       1558.0                    0.0  58.176122                  9.0   \n",
       "\n",
       "         num_tl_120dpd_2m  purpose_moving  open_act_il  num_tl_op_past_12m  \\\n",
       "51090                 0.0           False      2.79254                 2.0   \n",
       "1013926               0.0           False      2.79254                 2.0   \n",
       "779042                0.0           False      2.79254                 1.0   \n",
       "295164                0.0           False      2.79254                 6.0   \n",
       "1124251               0.0           False      2.79254                 2.0   \n",
       "\n",
       "         inq_last_6mths  num_bc_sats  \n",
       "51090               0.0          4.0  \n",
       "1013926             0.0          6.0  \n",
       "779042              1.0          2.0  \n",
       "295164              1.0          6.0  \n",
       "1124251             1.0          5.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport xgboost as xgb\\nimport pickle\\n\\n# Load the model from the pickle file\\nwith open('models/xgb_top20.pkl', 'rb') as file:\\n    xgbm = pickle.load(file)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open('models/xgb_top20.pkl', 'rb') as file:\n",
    "    xgbm = pickle.load(file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_ordered = xgbm.get_booster().feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the P2P Lending Environment\n",
    "class P2PLendingEnv(EnvBase):\n",
    "    def __init__(self, num_borrowers, num_lenders, borrower_features, xgboost_model):\n",
    "        super().__init__()\n",
    "        self.num_borrowers = num_borrowers\n",
    "        self.num_lenders = num_lenders\n",
    "        self.xgboost_model = xgboost_model\n",
    "        self.feature_dim = 20\n",
    "        \n",
    "        # Initialize borrowers and lenders\n",
    "        self.borrowers = [BorrowerAgent(self.feature_dim - 1) for _ in range(num_borrowers)]\n",
    "        self.lenders = [LenderAgent(self.feature_dim) for _ in range(num_lenders)]\n",
    "\n",
    "        # initialize borrower and lender weights randomly\n",
    "        for borrower in self.borrowers:\n",
    "            borrower.apply(init_weights)\n",
    "        for lender in self.lenders:\n",
    "            lender.apply(init_weights)\n",
    "\n",
    "        # Borrower features and hidden default probabilities\n",
    "        self.borrower_features = borrower_features\n",
    "        self.default_probs = [0] * self.num_borrowers # default probabilities for each borrower\n",
    "\n",
    "        # Action and observation specs\n",
    "        observation_spec = TensorSpec(torch.Size([self.feature_dim]), device=torch.device('cpu'), space=None)\n",
    "        self.observation_spec = CompositeSpec(observation=observation_spec)\n",
    "        self.action_spec = TensorSpec(torch.Size([1]), device=torch.device('cpu'), space=None)\n",
    "\n",
    "    def calculate_default_outcomes(self, int_rates):\n",
    "        \"\"\"\n",
    "        NOT USING XGB FOR NOW TO FIX TRAINING BUGS\n",
    "        Use XGB to set default outcome of each borrower based on interest rate chosen \n",
    "        \"\"\"\n",
    "\n",
    "        # default probability for each borrower is (int_rate - 6) / 30 \n",
    "\n",
    "        # Calculate default probabilities\n",
    "        default_probs = (int_rates - 6) / 30\n",
    "\n",
    "        # Sample default outcomes based on probabilities\n",
    "        self.default_probs = default_probs.squeeze(1)\n",
    "    \n",
    "    def _set_seed(self, seed):\n",
    "        pass\n",
    "\n",
    "    def _reset(self, **kwargs):\n",
    "        return self.borrower_features\n",
    "\n",
    "    def _step(self, borrower_actions, lender_actions):\n",
    "        rewards_lenders = []\n",
    "        rewards_borrowers = torch.zeros(self.num_borrowers)\n",
    "\n",
    "        for lender_idx in range(self.num_lenders):\n",
    "            borrower_actions = borrower_actions.clone()\n",
    "            lender_actions = lender_actions.clone()\n",
    "            funding_probs = lender_actions[lender_idx]\n",
    "            loan_amnts = torch.tensor(self.borrower_features['loan_amnt'].values.astype(np.float32))\n",
    "\n",
    "            pos_lender = (funding_probs * loan_amnts).sum() + (funding_probs * loan_amnts * borrower_actions).sum()\n",
    "            pos_borrowers = funding_probs * loan_amnts\n",
    "            neg_lender = (funding_probs * self.default_probs * loan_amnts).sum()\n",
    "            neg_borrowers = self.default_probs * loan_amnts\n",
    "\n",
    "            # Avoid in-place updates\n",
    "            borrower_reward_update = pos_borrowers - neg_borrowers\n",
    "            print(borrower_reward_update.shape)\n",
    "            lender_reward_update = pos_lender - neg_lender\n",
    "\n",
    "            rewards_borrowers = rewards_borrowers + borrower_reward_update\n",
    "            rewards_lenders.append(lender_reward_update)\n",
    "\n",
    "        return rewards_borrowers, rewards_lenders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torchrl/data/tensor_specs.py:5464: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.7. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/pg/r39s25yx6vn60b24nh6592th0000gn/T/ipykernel_16003/140917881.py\", line 38, in <module>\n",
      "    lender_actions = torch.stack([l(torch.flatten(lender_inputs)) for i, l in enumerate(env.lenders)]) # shape: (num_lenders, 5)\n",
      "  File \"/var/folders/pg/r39s25yx6vn60b24nh6592th0000gn/T/ipykernel_16003/140917881.py\", line 38, in <listcomp>\n",
      "    lender_actions = torch.stack([l(torch.flatten(lender_inputs)) for i, l in enumerate(env.lenders)]) # shape: (num_lenders, 5)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/var/folders/pg/r39s25yx6vn60b24nh6592th0000gn/T/ipykernel_16003/3295266646.py\", line 39, in forward\n",
      "    return self.model(x)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/simonlee/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      " (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:115.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0\n",
      "torch.Size([5, 19])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "Optimizing lender 0\n",
      "Tensor version before backward for lender 0: 0\n",
      "Optimizing lender 1\n",
      "Tensor version before backward for lender 1: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 5]], which is output 0 of AsStridedBackward0, is at version 3; expected version 2 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mrewards_lenders[i]  \u001b[38;5;66;03m# Maximize lender reward\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor version before backward for lender \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlender_actions\u001b[38;5;241m.\u001b[39m_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Update Borrowers\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Cypher/P2P RL/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 5]], which is output 0 of AsStridedBackward0, is at version 3; expected version 2 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_episodes = 200\n",
    "num_borrowers = 5\n",
    "num_lenders = 10\n",
    "\n",
    "# Load pre-trained XGBoost model\n",
    "xgboost_model = None  \n",
    "\n",
    "env = P2PLendingEnv(num_borrowers, num_lenders, sample, xgboost_model)\n",
    "borrower_optimizers = [optim.Adam(b.model.parameters(), lr=0.01) for b in env.borrowers]\n",
    "lender_optimizers = [optim.Adam(l.model.parameters(), lr=0.01) for l in env.lenders]\n",
    "\n",
    "borrower_loss = []\n",
    "lender_loss = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    print(\"Episode \", episode)\n",
    "    borrower_features = env._reset()\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    # Borrowers propose interest rates. borrower actions is proposed interest rate of each borrower.\n",
    "    borrower_actions = torch.stack([\n",
    "        b(normalize_borrower(\n",
    "            torch.tensor(borrower_features.iloc[i].values.astype(np.float32), dtype=torch.float32)\n",
    "        )) for i, b in enumerate(env.borrowers)\n",
    "    ])\n",
    "\n",
    "    #print(borrower_actions.shape)\n",
    "\n",
    "    # Default outcome is predicted using XGBoost model\n",
    "    env.calculate_default_outcomes(borrower_actions)\n",
    "\n",
    "    # Lenders decide to fund. output of each lender is a 5 element vector of funding decisions for each borrower. \n",
    "    borrower_features_tensor = torch.tensor(borrower_features.values.astype(np.float32), dtype=torch.float32)\n",
    "    print(borrower_features_tensor.shape)\n",
    "    lender_inputs = torch.cat((borrower_features_tensor, borrower_actions), dim=1)\n",
    "    lender_inputs = normalize_lender(lender_inputs)\n",
    "    lender_actions = torch.stack([l(torch.flatten(lender_inputs)) for i, l in enumerate(env.lenders)]) # shape: (num_lenders, 5)\n",
    "\n",
    "    # Step environment\n",
    "    rewards_borrowers, rewards_lenders = env._step(borrower_actions, lender_actions)\n",
    "\n",
    "    # Logging\n",
    "    \"\"\"\n",
    "    total_lender_loss = -rewards[:num_borrowers].sum().item()\n",
    "    total_borrower_loss = -rewards[num_borrowers:].sum().item()\n",
    "    borrower_loss.append(total_borrower_loss)\n",
    "    lender_loss.append(total_lender_loss)\n",
    "    \"\"\"\n",
    "\n",
    "    # Check gradients\n",
    "    \n",
    "    # Update Lenders\n",
    "    for i, optimizer in enumerate(lender_optimizers):\n",
    "        print(f\"Optimizing lender {i}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss = -rewards_lenders[i]  # Maximize lender reward\n",
    "        print(f\"Tensor version before backward for lender {i}: {lender_actions._version}\")\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Update Borrowers\n",
    "    for i, optimizer in enumerate(borrower_optimizers):\n",
    "        optimizer.zero_grad()\n",
    "        loss = -rewards_borrowers[i]  # Maximize borrower reward\n",
    "        loss.backward(retain_graph=True)\n",
    "        for name, param in env.borrowers[0].named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(f\"Gradients for {name}: {param.grad.norm().item()}\")\n",
    "            else:\n",
    "                print(f\"No gradients for {name}\")\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
